---
# defaults file for llm_tools
llm_base_config_path: "{{ config_root }}" # Base path for configuration files
llm_network_name: "llm-network"

# --- MCP-Proxy Settings ---
mcp_proxy_image_base: "ghcr.io/sparfenyuk/mcp-proxy:latest"
mcp_proxy_image_custom: "mcp-proxy:custom"
mcp_proxy_container_name: "mcp-proxy"
mcp_proxy_service_port: 8009 # Port mcp-proxy will listen on
mcp_proxy_config_dir_host: "{{ llm_base_config_path }}/mcp-proxy"
mcp_proxy_config_filename: "servers.json"

# --- LiteLLM Proxy Settings ---
litellm_proxy_image: "ghcr.io/berriai/litellm:main-latest"
litellm_proxy_container_name: "litellm-proxy-container"
litellm_proxy_config_dir_host: "{{ llm_base_config_path }}/litellm"
litellm_proxy_config_filename: "config.yaml"
litellm_proxy_port_host: "{{ litellm_proxy_port }}" # Host port for LiteLLM
litellm_proxy_port_container: "4000" # Container port for LiteLLM (default)
langfuse_host_for_litellm: "http://{{ homelab_nuc_ip }}:{{ langfuse_port }}"

# --- Open-WebUI Settings ---
ollama_base_url_for_webui: "http://{{ ollama_host }}:{{ ollama_port }}"

# --- Google Workspace MCP Settings ---
google_workspace_mcp_image: "ghcr.io/astral-sh/uv:debian"
google_workspace_mcp_container_name: "google-workspace-mcp"
google_workspace_mcp_port_host: 8014
google_workspace_mcp_port_container: 8000
