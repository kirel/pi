# llama-swap configuration
# Models to load and serve

models:
  {% for model in llamaswap_models -%}
  {{ model.alias }}:
    cmd: "{{ model.cmd }}"
    env:
      - "GGML_CUDA_MOUNT=/usr/lib/x86_64-linux-gnu/libcudart.so.12"
  {% endfor %}

# Global settings
server:
  # Allow CORS for web interfaces
  cors: true
  # Set timeout
  timeout: 3600

# Preload models on startup
hooks:
  on_startup:
    preload:
      - home
