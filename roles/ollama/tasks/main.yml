- name: Create volume
  community.docker.docker_volume:
    name: ollama_data

- name: Create temporary build directory
  ansible.builtin.tempfile:
    state: directory
    suffix: ollama_build
  register: build_dir

- name: Copy Dockerfile to build directory
  ansible.builtin.copy:
    src: "{{ role_path }}/Dockerfile.mcp-proxy"
    dest: "{{ build_dir.path }}/Dockerfile.mcp-proxy"
    mode: '0644'


- name: Start AI containers
  community.docker.docker_compose_v2:
    project_name: ai
    pull: "always"  # Keep setting for other images
    build: "always"
    state: present
    definition:
      services:
        ollama-service:
          image: ollama/ollama
          container_name: ollama
          restart: unless-stopped
          ports:
            - "11435:11434"
          environment:
            OLLAMA_DEBUG: "1"
            OLLAMA_NUM_PARALLEL: "2"
            OLLAMA_MAX_LOADED_MODELS: "2"
          volumes:
            - ollama_data:/root/.ollama
          labels:
            wud.tag.include: '^\d+\.\d+\.\d+$$'

        open-webui:
          image: ghcr.io/open-webui/open-webui:main
          container_name: open-webui
          restart: unless-stopped
          environment:
            OLLAMA_BASE_URL: "http://ollama-raw.lan:11434"
          volumes:
            - open-webui:/app/backend/data
          ports:
            - "{{ open_webui_http_port }}:8080"
          labels:
            wud.tag.include: 'main'
            wud.watch.digest: 'true'
            homepage.group: "{{ services['open-webui'].group }}"
            homepage.name: "{{ services['open-webui'].name }}"
            homepage.href: "https://ollama.lan"
            homepage.icon: openai.png
            homepage.server: "{{ inventory_hostname }}"
            homepage.container: open-webui

        todoist-mcp-server:
          image: mcp-base:latest
          build:
            context: "{{ build_dir.path }}"
            dockerfile: Dockerfile.mcp-proxy
          container_name: todoist-mcp-server
          restart: unless-stopped
          command: sh -c "uvx mcp-proxy --pass-environment --sse-host 0.0.0.0 --sse-port={{ todoist_mcp_proxy_port }} -- npx -y @chrusic/todoist-mcp-server-extended"
          environment:
            TODOIST_API_TOKEN: "{{ todoist_api_token }}"
          ports:
            - "{{ todoist_mcp_proxy_port }}:{{ todoist_mcp_proxy_port }}"

        todoist-mcp-server-python:
          image: mcp-base:latest
          build:
            context: "{{ build_dir.path }}"
            dockerfile: Dockerfile.mcp-proxy
          container_name: todoist-mcp-server-python
          restart: unless-stopped
          command: sh -c "uvx mcp-proxy --pass-environment --sse-host 0.0.0.0 --sse-port={{ todoist_mcp_py_proxy_port }} -- uvx --from https://github.com/kirel/todoist-mcp-python.git mcp-server-todoist"
          environment:
            TODOIST_API_TOKEN: "{{ todoist_api_token }}"
          ports:
            - "{{ todoist_mcp_py_proxy_port }}:{{ todoist_mcp_py_proxy_port }}"

        memory-mcp-server:
          image: mcp-base:latest
          build:
            context: "{{ build_dir.path }}"
            dockerfile: Dockerfile.mcp-proxy
          container_name: memory-mcp-server
          restart: unless-stopped
          command: sh -c "uvx mcp-proxy --pass-environment --sse-host 0.0.0.0 --sse-port={{ memory_mcp_proxy_port }} -- npx -y @modelcontextprotocol/server-memory"
          ports:
            - "{{ memory_mcp_proxy_port }}:{{ memory_mcp_proxy_port }}"

      volumes:
        ollama_data:
          external: true  # External volume for persistent data
        open-webui: {}  # Internal volume for web UI data
