---
- name: Create data folders
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: "0755"
    owner: "{{ uid }}"
    group: "{{ gid }}"
    recurse: yes
  with_items:
    - "{{ huggingface_cache_folder }}"
    - "{{ chatterbox_models_folder }}"
    - "{{ chatterbox_voices_folder }}"
    - "{{ chatterbox_longtext_data_folder }}"
    - "{{ chatterbox_frontend_build_folder }}"
  become: true

- name: Create voice sample file (placeholder)
  ansible.builtin.file:
    path: "{{ chatterbox_voice_sample_file }}"
    state: touch
    mode: "0644"
    owner: "{{ uid }}"
    group: "{{ gid }}"
  become: true

- name: Start wyoming_openai stack
  community.docker.docker_compose_v2:
    project_name: wyoming-openai
    state: present
    definition:
      services:
        init-speaches:
          container_name: init-speaches
          image: ghcr.io/speaches-ai/speaches:latest-cuda
          environment:
            - SPEACHES_BASE_URL={{ stt_openai_url }}
          command: >
            /bin/bash -c '
              curl -LsSf https://astral.sh/uv/install.sh | sh
              export PATH="/home/ubuntu/.local/bin:$PATH"
              uvx speaches-cli model download {{ stt_model }}
              uvx speaches-cli model download {{ tts_model }}
            '
          volumes:
            - "{{ huggingface_cache_folder }}:/home/ubuntu/.cache/huggingface/hub"
          runtime: nvidia
          deploy:
            resources:
              reservations:
                devices:
                  - driver: nvidia
                    capabilities: [gpu]
          restart: "no"
          depends_on:
            speaches:
              condition: service_started

        speaches:
          container_name: "{{ speaches_container_name }}"
          image: "{{ speaches_image }}"
          restart: unless-stopped
          ports:
            - "{{ ports.ailab_ubuntu.speaches }}:8000"
          environment:
            - enable_ui=False
            - log_level=info
            - WHISPER__MODEL={{ stt_model }}
            - WHISPER__compute_type=int8_float32
          volumes:
            - "{{ huggingface_cache_folder }}:/home/ubuntu/.cache/huggingface/hub"
          healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
          labels:
            - "wud.tag.include=^v\\d+\\.\\d+\\.\\d+$"
          deploy:
            resources:
              reservations:
                devices:
                  - driver: nvidia
                    device_ids: ["{{ blackwell_gpu_uuid }}"]
                    capabilities: ["gpu"]

        chatterbox-tts:
          container_name: "{{ chatterbox_container_name }}"
          # Use build context with uv-optimized Dockerfile for better performance
          build:
            context: https://github.com/travisvn/chatterbox-tts-api.git#main
            dockerfile: docker/Dockerfile.blackwell
          restart: unless-stopped
          ports:
            - "{{ ports.ailab_ubuntu.chatterbox_tts }}:4123"
          environment:
            # Server Configuration
            - PORT=4123
            - HOST=0.0.0.0
            - CORS_ORIGINS={{ chatterbox_cors_origins }}
            # TTS Model Settings
            - EXAGGERATION={{ chatterbox_exaggeration }}
            - CFG_WEIGHT={{ chatterbox_cfg_weight }}
            - TEMPERATURE={{ chatterbox_temperature }}
            - USE_MULTILINGUAL_MODEL={{ chatterbox_use_multilingual_model | string | lower }}
            # Text Processing
            - MAX_CHUNK_LENGTH={{ chatterbox_max_chunk_length }}
            - MAX_TOTAL_LENGTH={{ chatterbox_max_total_length }}
            # Long Text TTS Settings
            - LONG_TEXT_DATA_DIR=/data/long_text_jobs
            - LONG_TEXT_MAX_LENGTH={{ chatterbox_longtext_max_length }}
            - LONG_TEXT_CHUNK_SIZE={{ chatterbox_longtext_chunk_size }}
            - LONG_TEXT_SILENCE_PADDING_MS={{ chatterbox_longtext_silence_padding_ms }}
            - LONG_TEXT_JOB_RETENTION_DAYS={{ chatterbox_longtext_job_retention_days }}
            - LONG_TEXT_MAX_CONCURRENT_JOBS={{ chatterbox_longtext_max_concurrent_jobs }}
            # Voice and Model Settings
            - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
            - DEVICE={{ chatterbox_device }}
            - MODEL_CACHE_DIR=/cache
            - VOICE_LIBRARY_DIR=/voices
            # NVIDIA/CUDA settings
            - NVIDIA_VISIBLE_DEVICES=all
            - NVIDIA_DRIVER_CAPABILITIES=compute,utility
            # Memory Management
            - MEMORY_CLEANUP_INTERVAL={{ chatterbox_memory_cleanup_interval }}
            - CUDA_CACHE_CLEAR_INTERVAL={{ chatterbox_cuda_cache_clear_interval }}
            - ENABLE_MEMORY_MONITORING={{ chatterbox_enable_memory_monitoring | string | lower }}
          volumes:
            - "{{ chatterbox_voice_sample_file }}:/app/voice-sample.mp3:ro"
            - "{{ chatterbox_models_folder }}:/cache"
            - "{{ chatterbox_voices_folder }}:/voices"
            - "{{ chatterbox_longtext_data_folder }}:/data/long_text_jobs"
          healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:4123/health"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 300s
          deploy:
            resources:
              reservations:
                devices:
                  - driver: nvidia
                    device_ids: ["{{ blackwell_gpu_uuid }}"]
                    capabilities: [gpu]

        chatterbox-frontend:
          build:
            context: https://github.com/travisvn/chatterbox-tts-api.git#main:frontend
            dockerfile: Dockerfile
          container_name: chatterbox-tts-frontend
          ports:
            - "{{ ports.ailab_ubuntu.chatterbox_ui }}:80"
          depends_on:
            - chatterbox-tts
          restart: unless-stopped

        wyoming_openai:
          container_name: "{{ wyoming_openai_container_name }}"
          image: "{{ wyoming_openai_image }}"
          restart: unless-stopped
          ports:
            - "{{ ports.ailab_ubuntu.wyoming_openai }}:10300"
          environment:
            WYOMING_URI: "{{ wyoming_uri }}"
            WYOMING_LOG_LEVEL: "{{ wyoming_log_level }}"
            WYOMING_LANGUAGES: "{{ wyoming_languages }}"
            STT_OPENAI_URL: "{{ stt_openai_url }}"
            STT_MODELS: "{{ stt_model }}"
            STT_BACKEND: "{{ stt_backend }}"
            TTS_OPENAI_URL: "{{ tts_openai_url }}"
            TTS_MODELS: "{{ tts_model }}"
            TTS_BACKEND: "{{ tts_backend }}"
            TTS_VOICES: "{{ tts_voices }}"
            TTS_SPEED: "{{ tts_speed }}"
            # Enable streaming for your models
            # STT_STREAMING_MODELS: "{{ stt_streaming_models }}"
            TTS_STREAMING_MODELS: "{{ tts_streaming_models }}"
            TTS_STREAMING_MIN_WORDS: "{{ tts_streaming_min_words }}"
            TTS_STREAMING_MAX_CHARS: "{{ tts_streaming_max_chars }}"
            INVALIDATE: "3"  # increment to force redeploy
          depends_on:
            speaches:
              condition: service_healthy
            chatterbox-tts:
              condition: service_healthy
          labels:
            - "wud.tag.include=^v\\d+\\.\\d+\\.\\d+$"

        wyoming_openai_chatterbox:
          container_name: "{{ wyoming_openai_chatterbox_container_name }}"
          image: "{{ wyoming_openai_image }}"
          restart: unless-stopped
          ports:
            - "{{ ports.ailab_ubuntu.wyoming_chatterbox }}:10301"
          environment:
            WYOMING_URI: "{{ wyoming_chatterbox_uri }}"
            WYOMING_LOG_LEVEL: "{{ wyoming_log_level }}"
            WYOMING_LANGUAGES: "{{ wyoming_languages }}"
            # Chatterbox Gateway is TTS only - no STT configuration
            TTS_OPENAI_URL: "http://chatterbox-tts:4123/v1"
            TTS_MODELS: "{{ chatterbox_use_multilingual_model | string | lower }}"
            TTS_BACKEND: "{{ wyoming_chatterbox_tts_backend }}"
            TTS_VOICES: "{{ chatterbox_voices }}"
            # No TTS_SPEED (Chatterbox handles this internally)
            # Enable streaming for TTS
            TTS_STREAMING_MODELS: "chatterbox-tts-1"
            TTS_STREAMING_MIN_WORDS: "{{ tts_streaming_min_words }}"
            TTS_STREAMING_MAX_CHARS: "{{ tts_streaming_max_chars }}"
            INVALIDATE: "1"  # increment to force redeploy
          depends_on:
            chatterbox-tts:
              condition: service_healthy
          labels:
            - "wud.tag.include=^v\\d+\\.\\d+\\.\\d+$"
